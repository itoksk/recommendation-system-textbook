# Chapter 6: å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - ãƒŸãƒ‹Twitterã‚’ä½œã‚ã†ï¼ ğŸ¦

## ğŸ¯ ã“ã®ç« ã®ã‚´ãƒ¼ãƒ«

ã“ã‚Œã¾ã§å­¦ã‚“ã å…¨ã¦ã®æŠ€è¡“ã‚’çµ±åˆã—ã¦ã€å®Ÿéš›ã«å‹•ã**ãƒŸãƒ‹Twitteræ¨è–¦ã‚·ã‚¹ãƒ†ãƒ **ã‚’æ§‹ç¯‰ã—ã¾ã™ï¼

- SimClustersã®å®Ÿè£…
- Light/Heavy Rankerã®æ§‹ç¯‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
- A/Bãƒ†ã‚¹ãƒˆã®å®Ÿè£…
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```python
class MiniTwitterArchitecture:
    """
    ãƒŸãƒ‹Twitterã®å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼š
    1. ãƒ‡ãƒ¼ã‚¿å±¤ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ãƒ„ã‚¤ãƒ¼ãƒˆã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
    2. ç‰¹å¾´é‡å±¤ï¼ˆé™çš„ã€å‹•çš„ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
    3. æ¨è–¦å±¤ï¼ˆSimClustersã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
    4. é…ä¿¡å±¤ï¼ˆã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ç”Ÿæˆï¼‰
    5. è©•ä¾¡å±¤ï¼ˆA/Bãƒ†ã‚¹ãƒˆã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰
    """
    
    def __init__(self):
        # ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢
        self.user_store = UserStore()
        self.tweet_store = TweetStore()
        self.interaction_store = InteractionStore()
        
        # æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ 
        self.simclusters = SimClustersEngine()
        self.light_ranker = LightRankingEngine()
        self.heavy_ranker = HeavyRankingEngine()
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
        self.stream_processor = StreamProcessor()
        self.feature_store = FeatureStore()
        
        # é…ä¿¡
        self.timeline_builder = TimelineBuilder()
        
        # è©•ä¾¡
        self.ab_test_manager = ABTestManager()
        self.metrics_collector = MetricsCollector()
```

## ğŸ“¦ å®Œå…¨å®Ÿè£…ï¼šãƒŸãƒ‹Twitterã‚·ã‚¹ãƒ†ãƒ 

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«

```python
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Set, Optional
import uuid

@dataclass
class User:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¢ãƒ‡ãƒ«"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    username: str = ""
    name: str = ""
    bio: str = ""
    created_at: datetime = field(default_factory=datetime.now)
    follower_count: int = 0
    following_count: int = 0
    tweet_count: int = 0
    verified: bool = False
    
    # æ¨è–¦ç”¨ã®å±æ€§
    simcluster_embedding: List[float] = field(default_factory=list)
    tweepcred_score: float = 50.0
    interests: List[str] = field(default_factory=list)
    
@dataclass
class Tweet:
    """ãƒ„ã‚¤ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    author_id: str = ""
    content: str = ""
    created_at: datetime = field(default_factory=datetime.now)
    
    # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ
    like_count: int = 0
    retweet_count: int = 0
    reply_count: int = 0
    impression_count: int = 0
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç‰¹å¾´
    has_media: bool = False
    has_url: bool = False
    language: str = "ja"
    
    # æ¨è–¦ç”¨
    simcluster_embedding: List[float] = field(default_factory=list)
    quality_score: float = 0.0
    
@dataclass
class Interaction:
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«"""
    user_id: str
    tweet_id: str
    type: str  # 'like', 'retweet', 'reply', 'impression'
    timestamp: datetime = field(default_factory=datetime.now)
    dwell_time_seconds: float = 0.0
```

### 2. SimClustersã‚¨ãƒ³ã‚¸ãƒ³

```python
import numpy as np
from sklearn.cluster import SpectralClustering
from collections import defaultdict

class SimClustersEngine:
    """SimClusterså®Ÿè£…"""
    
    def __init__(self, n_clusters=100):
        self.n_clusters = n_clusters
        self.known_for = {}  # producer -> cluster
        self.interested_in = {}  # consumer -> cluster_vector
        self.tweet_clusters = {}  # tweet -> cluster_vector
        
    def train(self, follow_graph: Dict[str, Set[str]], interactions: List[Interaction]):
        """SimClustersãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
        print("ğŸ”¨ SimClusterså­¦ç¿’é–‹å§‹...")
        
        # Step 1: Produceré¡ä¼¼åº¦ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
        producer_similarity = self._build_producer_similarity(follow_graph)
        
        # Step 2: ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        clustering = SpectralClustering(
            n_clusters=self.n_clusters,
            affinity='precomputed',
            random_state=42
        )
        
        producers = list(producer_similarity.keys())
        similarity_matrix = self._create_similarity_matrix(producer_similarity)
        
        labels = clustering.fit_predict(similarity_matrix)
        
        # Step 3: KnownForè¡Œåˆ—
        for producer, label in zip(producers, labels):
            self.known_for[producer] = label
            
        # Step 4: InterestedInè¡Œåˆ—
        for consumer, followed in follow_graph.items():
            interest_vector = np.zeros(self.n_clusters)
            for producer in followed:
                if producer in self.known_for:
                    cluster = self.known_for[producer]
                    interest_vector[cluster] += 1
                    
            # æ­£è¦åŒ–
            if interest_vector.sum() > 0:
                interest_vector /= interest_vector.sum()
            self.interested_in[consumer] = interest_vector
            
        # Step 5: TweetåŸ‹ã‚è¾¼ã¿
        self._compute_tweet_embeddings(interactions)
        
        print(f"âœ… SimClusterså­¦ç¿’å®Œäº†: {self.n_clusters}ã‚¯ãƒ©ã‚¹ã‚¿")
        
    def _build_producer_similarity(self, follow_graph):
        """Produceré–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        producer_followers = defaultdict(set)
        
        for consumer, producers in follow_graph.items():
            for producer in producers:
                producer_followers[producer].add(consumer)
                
        similarities = {}
        producers = list(producer_followers.keys())
        
        for i, p1 in enumerate(producers):
            for p2 in producers[i+1:]:
                followers1 = producer_followers[p1]
                followers2 = producer_followers[p2]
                
                if followers1 and followers2:
                    jaccard = len(followers1 & followers2) / len(followers1 | followers2)
                    if jaccard > 0.01:
                        similarities[(p1, p2)] = jaccard
                        
        return similarities
    
    def _compute_tweet_embeddings(self, interactions):
        """ãƒ„ã‚¤ãƒ¼ãƒˆåŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—"""
        tweet_likes = defaultdict(list)
        
        for interaction in interactions:
            if interaction.type == 'like':
                tweet_likes[interaction.tweet_id].append(interaction.user_id)
                
        for tweet_id, users in tweet_likes.items():
            embedding = np.zeros(self.n_clusters)
            
            for user_id in users:
                if user_id in self.interested_in:
                    embedding += self.interested_in[user_id]
                    
            # æ­£è¦åŒ–
            if embedding.sum() > 0:
                embedding /= embedding.sum()
                
            self.tweet_clusters[tweet_id] = embedding
    
    def get_recommendations(self, user_id: str, n: int = 20) -> List[tuple]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ¨è–¦"""
        if user_id not in self.interested_in:
            return []
            
        user_interest = self.interested_in[user_id]
        recommendations = []
        
        for tweet_id, tweet_embedding in self.tweet_clusters.items():
            score = np.dot(user_interest, tweet_embedding)
            recommendations.append((tweet_id, score))
            
        recommendations.sort(key=lambda x: x[1], reverse=True)
        return recommendations[:n]
```

### 3. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³

```python
class LightRankingEngine:
    """è»½é‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.feature_extractors = [
            self._extract_engagement_features,
            self._extract_content_features,
            self._extract_temporal_features,
        ]
        
    def score(self, tweet: Tweet, user: User, context: Dict) -> float:
        """è»½é‡ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""
        features = []
        
        for extractor in self.feature_extractors:
            features.extend(extractor(tweet, user, context))
            
        # ç°¡å˜ãªç·šå½¢çµåˆ
        weights = [0.3, 0.2, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05]
        score = sum(f * w for f, w in zip(features, weights))
        
        return score
    
    def _extract_engagement_features(self, tweet, user, context):
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‰¹å¾´"""
        return [
            tweet.like_count / (tweet.impression_count + 1),
            tweet.retweet_count / (tweet.impression_count + 1),
            np.log1p(tweet.like_count),
            np.log1p(tweet.retweet_count),
        ]
    
    def _extract_content_features(self, tweet, user, context):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç‰¹å¾´"""
        return [
            float(tweet.has_media),
            float(tweet.has_url),
            min(1.0, len(tweet.content) / 280),
        ]
    
    def _extract_temporal_features(self, tweet, user, context):
        """æ™‚é–“ç‰¹å¾´"""
        age_hours = (context['current_time'] - tweet.created_at).total_seconds() / 3600
        return [
            np.exp(-age_hours / 24),  # 24æ™‚é–“æ¸›è¡°
            float(age_hours < 1),     # 1æ™‚é–“ä»¥å†…
        ]

class HeavyRankingEngine:
    """é‡é‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆè©³ç´°ç‰ˆï¼‰"""
    
    def __init__(self):
        self.light_ranker = LightRankingEngine()
        
    def score(self, tweet: Tweet, user: User, context: Dict) -> float:
        """è©³ç´°ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""
        # Light Rankerã®ã‚¹ã‚³ã‚¢
        light_score = self.light_ranker.score(tweet, user, context)
        
        # è¿½åŠ ã®è¤‡é›‘ãªç‰¹å¾´
        author_score = self._get_author_score(tweet, user)
        similarity_score = self._get_similarity_score(tweet, user)
        social_proof_score = self._get_social_proof(tweet, user, context)
        
        # é‡ã¿ä»˜ãçµåˆ
        final_score = (
            light_score * 0.3 +
            author_score * 0.3 +
            similarity_score * 0.2 +
            social_proof_score * 0.2
        )
        
        return final_score
    
    def _get_author_score(self, tweet, user):
        """è‘—è€…ã‚¹ã‚³ã‚¢ï¼ˆTweepcredç­‰ï¼‰"""
        # ç°¡ç•¥ç‰ˆ
        return tweet.author.tweepcred_score / 100
    
    def _get_similarity_score(self, tweet, user):
        """é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢"""
        if len(tweet.simcluster_embedding) and len(user.simcluster_embedding):
            return np.dot(tweet.simcluster_embedding, user.simcluster_embedding)
        return 0.5
    
    def _get_social_proof(self, tweet, user, context):
        """ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ—ãƒ«ãƒ¼ãƒ•"""
        # ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ã„ã‚‹äººãŒã„ã„ã­ã—ã¦ã„ã‚‹ã‹ç­‰
        friends_who_liked = context.get('friends_engagements', {}).get(tweet.id, 0)
        return min(1.0, friends_who_liked / 10)
```

### 4. ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ“ãƒ«ãƒ€ãƒ¼

```python
class TimelineBuilder:
    """ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³æ§‹ç¯‰"""
    
    def __init__(self, simclusters: SimClustersEngine,
                 light_ranker: LightRankingEngine,
                 heavy_ranker: HeavyRankingEngine):
        self.simclusters = simclusters
        self.light_ranker = light_ranker
        self.heavy_ranker = heavy_ranker
        
    def build_timeline(self, user: User, algorithm: str = 'hybrid') -> List[Tweet]:
        """ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰"""
        
        if algorithm == 'chronological':
            return self._build_chronological(user)
        elif algorithm == 'simclusters':
            return self._build_simclusters(user)
        elif algorithm == 'hybrid':
            return self._build_hybrid(user)
            
    def _build_hybrid(self, user: User) -> List[Tweet]:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ï¼ˆTwitterã®"For You"ï¼‰"""
        
        # Step 1: å€™è£œç”Ÿæˆï¼ˆè¤‡æ•°ã‚½ãƒ¼ã‚¹ï¼‰
        candidates = []
        
        # In-networkï¼ˆãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ã„ã‚‹äººï¼‰
        in_network = self._get_in_network_tweets(user)
        candidates.extend(in_network[:500])
        
        # Out-of-networkï¼ˆSimClustersï¼‰
        simcluster_recs = self.simclusters.get_recommendations(user.id, 500)
        out_network = [self.get_tweet(tid) for tid, _ in simcluster_recs]
        candidates.extend(out_network)
        
        # Trending
        trending = self._get_trending_tweets()
        candidates.extend(trending[:100])
        
        # Step 2: Light Ranking
        context = self._create_context(user)
        light_scores = []
        
        for tweet in candidates:
            score = self.light_ranker.score(tweet, user, context)
            light_scores.append((tweet, score))
            
        # Top 500ã‚’é¸æŠ
        light_scores.sort(key=lambda x: x[1], reverse=True)
        top_candidates = [tweet for tweet, _ in light_scores[:500]]
        
        # Step 3: Heavy Rankingï¼ˆä¸Šä½ã®ã¿ï¼‰
        final_scores = []
        
        for tweet in top_candidates[:100]:  # ä¸Šä½100ä»¶ã®ã¿
            score = self.heavy_ranker.score(tweet, user, context)
            final_scores.append((tweet, score))
            
        # Light Rankerã®çµæœã‚‚å«ã‚ã‚‹
        for tweet, light_score in light_scores[100:500]:
            final_scores.append((tweet, light_score * 0.7))  # é‡ã¿ä¸‹ã’
            
        # Step 4: æœ€çµ‚ã‚½ãƒ¼ãƒˆ
        final_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Step 5: å¤šæ§˜æ€§ãƒ•ã‚£ãƒ«ã‚¿
        timeline = self._apply_diversity_filter(
            [tweet for tweet, _ in final_scores]
        )
        
        return timeline[:20]
    
    def _apply_diversity_filter(self, tweets: List[Tweet]) -> List[Tweet]:
        """å¤šæ§˜æ€§ãƒ•ã‚£ãƒ«ã‚¿"""
        filtered = []
        seen_authors = set()
        seen_topics = set()
        
        for tweet in tweets:
            # åŒã˜è‘—è€…ã®åˆ¶é™
            if tweet.author_id in seen_authors:
                if len([t for t in filtered if t.author_id == tweet.author_id]) >= 2:
                    continue
                    
            # ãƒˆãƒ”ãƒƒã‚¯ã®å¤šæ§˜æ€§
            # ï¼ˆç°¡ç•¥åŒ–ï¼‰
            
            filtered.append(tweet)
            seen_authors.add(tweet.author_id)
            
            if len(filtered) >= 50:
                break
                
        return filtered
```

### 5. A/Bãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 

```python
import hashlib
from enum import Enum

class ExperimentGroup(Enum):
    CONTROL = "control"
    TREATMENT = "treatment"

class ABTestManager:
    """A/Bãƒ†ã‚¹ãƒˆç®¡ç†"""
    
    def __init__(self):
        self.experiments = {}
        self.results = defaultdict(lambda: {
            'control': {'impressions': 0, 'engagements': 0},
            'treatment': {'impressions': 0, 'engagements': 0}
        })
        
    def create_experiment(self, name: str, treatment_percentage: float = 0.1):
        """å®Ÿé¨“ã‚’ä½œæˆ"""
        self.experiments[name] = {
            'name': name,
            'treatment_percentage': treatment_percentage,
            'start_time': datetime.now(),
            'is_active': True
        }
        
    def get_user_group(self, user_id: str, experiment_name: str) -> ExperimentGroup:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿé¨“ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ±ºå®š"""
        if experiment_name not in self.experiments:
            return ExperimentGroup.CONTROL
            
        experiment = self.experiments[experiment_name]
        if not experiment['is_active']:
            return ExperimentGroup.CONTROL
            
        # å®‰å®šã—ãŸãƒãƒƒã‚·ãƒ¥ã§å‰²ã‚Šå½“ã¦
        hash_input = f"{user_id}:{experiment_name}"
        hash_value = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)
        
        percentage = (hash_value % 100) / 100
        
        if percentage < experiment['treatment_percentage']:
            return ExperimentGroup.TREATMENT
        else:
            return ExperimentGroup.CONTROL
    
    def log_impression(self, user_id: str, tweet_id: str, experiment_name: str):
        """ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚’è¨˜éŒ²"""
        group = self.get_user_group(user_id, experiment_name)
        self.results[experiment_name][group.value]['impressions'] += 1
        
    def log_engagement(self, user_id: str, tweet_id: str, 
                       engagement_type: str, experiment_name: str):
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’è¨˜éŒ²"""
        group = self.get_user_group(user_id, experiment_name)
        self.results[experiment_name][group.value]['engagements'] += 1
        
    def get_results(self, experiment_name: str) -> Dict:
        """å®Ÿé¨“çµæœã‚’å–å¾—"""
        if experiment_name not in self.results:
            return {}
            
        results = self.results[experiment_name]
        
        # CTRè¨ˆç®—
        control_ctr = (results['control']['engagements'] / 
                      max(1, results['control']['impressions']))
        treatment_ctr = (results['treatment']['engagements'] / 
                        max(1, results['treatment']['impressions']))
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§ã®è¨ˆç®—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        lift = ((treatment_ctr - control_ctr) / max(0.001, control_ctr)) * 100
        
        return {
            'control': {
                'impressions': results['control']['impressions'],
                'engagements': results['control']['engagements'],
                'ctr': control_ctr
            },
            'treatment': {
                'impressions': results['treatment']['impressions'],
                'engagements': results['treatment']['engagements'],
                'ctr': treatment_ctr
            },
            'lift_percentage': lift,
            'is_significant': abs(lift) > 5  # ç°¡ç•¥åŒ–
        }
```

### 6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
import cachetools

class OptimizedTimelineBuilder:
    """æœ€é©åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ“ãƒ«ãƒ€ãƒ¼"""
    
    def __init__(self):
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.timeline_cache = cachetools.TTLCache(maxsize=10000, ttl=60)
        self.feature_cache = cachetools.LRUCache(maxsize=100000)
        
        # ä¸¦åˆ—å‡¦ç†
        self.executor = ThreadPoolExecutor(max_workers=10)
        
    async def build_timeline_optimized(self, user_id: str) -> List[Tweet]:
        """æœ€é©åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³æ§‹ç¯‰"""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cache_key = f"timeline:{user_id}"
        if cache_key in self.timeline_cache:
            return self.timeline_cache[cache_key]
            
        # ä¸¦åˆ—ã§å€™è£œå–å¾—
        tasks = [
            self._fetch_in_network_async(user_id),
            self._fetch_simclusters_async(user_id),
            self._fetch_trending_async()
        ]
        
        results = await asyncio.gather(*tasks)
        candidates = []
        for result in results:
            candidates.extend(result)
            
        # ãƒãƒƒãƒã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        scored = await self._batch_score_async(candidates, user_id)
        
        # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        timeline = scored[:20]
        self.timeline_cache[cache_key] = timeline
        
        return timeline
    
    async def _batch_score_async(self, tweets: List[Tweet], user_id: str):
        """ãƒãƒƒãƒã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""
        # ç‰¹å¾´é‡ã‚’ä¸¦åˆ—æŠ½å‡º
        feature_tasks = []
        for tweet in tweets:
            task = self._extract_features_async(tweet, user_id)
            feature_tasks.append(task)
            
        features = await asyncio.gather(*feature_tasks)
        
        # ãƒãƒƒãƒäºˆæ¸¬
        scores = self._batch_predict(features)
        
        # ã‚½ãƒ¼ãƒˆ
        scored_tweets = list(zip(tweets, scores))
        scored_tweets.sort(key=lambda x: x[1], reverse=True)
        
        return [tweet for tweet, _ in scored_tweets]
```

## ğŸ® çµ±åˆãƒ†ã‚¹ãƒˆ

```python
def run_integrated_test():
    """çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ ãƒŸãƒ‹Twitterçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = MiniTwitterArchitecture()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    users = create_test_users(100)
    tweets = create_test_tweets(1000)
    interactions = create_test_interactions(10000)
    
    # SimClusterså­¦ç¿’
    follow_graph = create_follow_graph(users)
    system.simclusters.train(follow_graph, interactions)
    
    # A/Bãƒ†ã‚¹ãƒˆè¨­å®š
    system.ab_test_manager.create_experiment(
        "heavy_ranker_v2",
        treatment_percentage=0.1
    )
    
    # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    for user in users[:10]:
        timeline = system.timeline_builder.build_timeline(user, 'hybrid')
        print(f"User {user.username}: {len(timeline)} tweets")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        for tweet in timeline:
            system.ab_test_manager.log_impression(
                user.id, tweet.id, "heavy_ranker_v2"
            )
    
    # çµæœè¡¨ç¤º
    results = system.ab_test_manager.get_results("heavy_ranker_v2")
    print(f"A/Bãƒ†ã‚¹ãƒˆçµæœ: {results}")
    
    print("âœ… çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†ï¼")

if __name__ == "__main__":
    run_integrated_test()
```

## ğŸ¯ æœ€çµ‚èª²é¡Œ

### èª²é¡Œ1: ç‹¬è‡ªã®æ¨è–¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
ã‚ãªãŸç‹¬è‡ªã®æ¨è–¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

### èª²é¡Œ2: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
WebSocketã‚’ä½¿ã£ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

### èª²é¡Œ3: å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œã‚’å¯è¦–åŒ–ã™ã‚‹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ğŸŠ ãŠã‚ã§ã¨ã†ï¼

ã“ã‚Œã§ã€X(Twitter)ãƒ¬ãƒ™ãƒ«ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®åŸºç¤ã‚’å…¨ã¦ãƒã‚¹ã‚¿ãƒ¼ã—ã¾ã—ãŸï¼

å­¦ã‚“ã ã“ã¨ï¼š
- âœ… æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®åŸºç¤ç†è«–
- âœ… å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨SimClusters
- âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°
- âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªè¨­è¨ˆ
- âœ… å®Ÿè·µçš„ãªå®Ÿè£…

æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼š
- å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™
- æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ·±ã‚ã‚‹
- ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤

é ‘å¼µã£ã¦ãã ã•ã„ï¼ ğŸš€