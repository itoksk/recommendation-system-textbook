# Chapter 4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚° ğŸ¯

## ğŸ“š ã“ã®ç« ã§å­¦ã¶ã“ã¨

- Twitterã®Light/Heavy Rankerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè·µ
- æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å°å…¥
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰¹å¾´é‡ã®ç®¡ç†

## ğŸ—ï¸ Twitterã®2æ®µéšãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

### ãªãœ2æ®µéšãªã®ã‹ï¼Ÿ

```python
class TwoStageRankingSystem:
    """
    Twitterã®2æ®µéšãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®è€ƒãˆæ–¹
    
    å•é¡Œï¼š
    - å€™è£œãŒå¤šã™ãã‚‹ï¼ˆæ•°åä¸‡ãƒ„ã‚¤ãƒ¼ãƒˆï¼‰
    - Heavy Rankerã¯é«˜ç²¾åº¦ã ãŒé…ã„ï¼ˆ1ãƒ„ã‚¤ãƒ¼ãƒˆ10msï¼‰
    - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒå¿…è¦ï¼ˆ< 100msï¼‰
    
    è§£æ±ºï¼š
    1. Light Ranker: é«˜é€Ÿãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ0.1ms/ãƒ„ã‚¤ãƒ¼ãƒˆï¼‰
    2. Heavy Ranker: ç²¾å¯†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆ10ms/ãƒ„ã‚¤ãƒ¼ãƒˆï¼‰
    """
    
    def __init__(self):
        self.light_ranker = LightRanker()
        self.heavy_ranker = HeavyRanker()
        
    def rank(self, candidates, user_context):
        # Stage 1: Light Rankingï¼ˆæ•°åä¸‡ â†’ 1000ï¼‰
        light_scored = self.light_ranker.score_batch(candidates)
        top_candidates = self.filter_top_k(light_scored, k=1000)
        
        # Stage 2: Heavy Rankingï¼ˆ1000 â†’ 20ï¼‰
        final_scores = self.heavy_ranker.score_batch(top_candidates, user_context)
        final_ranking = self.sort_by_score(final_scores)
        
        return final_ranking[:20]
```

## ğŸª¶ Light Ranker: é«˜é€Ÿã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

### Light Rankerã®å®Ÿè£…

```python
import numpy as np
from sklearn.linear_model import LogisticRegression

class LightRanker:
    """
    Twitterã®è»½é‡ãƒ©ãƒ³ã‚«ãƒ¼
    - ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆå¤ã„ãŒé«˜é€Ÿï¼‰
    - æœ€å°é™ã®ç‰¹å¾´é‡ï¼ˆã€œ100æ¬¡å…ƒï¼‰
    - ãƒãƒƒãƒå‡¦ç†ã§é«˜é€ŸåŒ–
    """
    
    def __init__(self):
        self.model = LogisticRegression()
        self.feature_extractors = [
            self.extract_engagement_features,
            self.extract_content_features,
            self.extract_author_features,
            self.extract_temporal_features
        ]
        
    def extract_features(self, tweet, user):
        """è»½é‡ãªç‰¹å¾´é‡æŠ½å‡º"""
        features = []
        
        for extractor in self.feature_extractors:
            features.extend(extractor(tweet, user))
            
        return np.array(features)
    
    def extract_engagement_features(self, tweet, user):
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‰¹å¾´ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰"""
        return [
            tweet.like_count,
            tweet.retweet_count,
            tweet.reply_count,
            np.log1p(tweet.like_count),  # å¯¾æ•°å¤‰æ›
            np.log1p(tweet.retweet_count),
            tweet.like_count / (tweet.impression_count + 1),  # CTR
            tweet.retweet_count / (tweet.impression_count + 1),
        ]
    
    def extract_content_features(self, tweet, user):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç‰¹å¾´ï¼ˆé™çš„ï¼‰"""
        return [
            int(tweet.has_media),
            int(tweet.has_url),
            int(tweet.has_hashtag),
            int(tweet.is_reply),
            int(tweet.is_retweet),
            len(tweet.text),
            tweet.text.count('!'),
            tweet.text.count('?'),
            int('http' in tweet.text),
        ]
    
    def extract_author_features(self, tweet, user):
        """è‘—è€…ç‰¹å¾´"""
        author = tweet.author
        return [
            author.follower_count,
            author.following_count,
            np.log1p(author.follower_count),
            author.follower_count / (author.following_count + 1),
            author.verified,
            author.tweet_count,
            author.account_age_days,
            self.get_author_quality_score(author),  # Tweepcred
        ]
    
    def extract_temporal_features(self, tweet, user):
        """æ™‚é–“ç‰¹å¾´"""
        age_minutes = (datetime.now() - tweet.created_at).total_seconds() / 60
        
        return [
            age_minutes,
            np.exp(-age_minutes / 1440),  # 24æ™‚é–“æ¸›è¡°
            int(tweet.created_at.hour),  # æŠ•ç¨¿æ™‚é–“
            int(tweet.created_at.weekday()),  # æ›œæ—¥
            int(age_minutes < 60),  # 1æ™‚é–“ä»¥å†…
            int(age_minutes < 1440),  # 24æ™‚é–“ä»¥å†…
        ]
    
    def score_batch(self, tweets, user, batch_size=1000):
        """ãƒãƒƒãƒå‡¦ç†ã§é«˜é€ŸåŒ–"""
        all_scores = []
        
        for i in range(0, len(tweets), batch_size):
            batch = tweets[i:i+batch_size]
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            feature_matrix = np.array([
                self.extract_features(tweet, user) for tweet in batch
            ])
            
            # ä¸€æ‹¬äºˆæ¸¬
            scores = self.model.predict_proba(feature_matrix)[:, 1]
            all_scores.extend(scores)
            
        return all_scores
```

## ğŸ‹ï¸ Heavy Ranker: ç²¾å¯†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

### ClemNetã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆTwitterå®Ÿè£…ï¼‰

```python
import tensorflow as tf
from tensorflow.keras import layers, Model

class HeavyRanker:
    """
    Twitterã®Heavy Rankerï¼ˆClemNetï¼‰
    - æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
    - 6000+æ¬¡å…ƒã®ç‰¹å¾´é‡
    - ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’
    """
    
    def __init__(self, feature_dim=6000):
        self.feature_dim = feature_dim
        self.model = self.build_clemnet()
        
    def build_clemnet(self):
        """
        ClemNet: Twitterã®ç‹¬è‡ªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
        Conv1D + Dense + Residualæ¥ç¶š
        """
        inputs = layers.Input(shape=(self.feature_dim,))
        
        # ç‰¹å¾´é‡ã‚’3æ¬¡å…ƒã«å¤‰å½¢ï¼ˆConv1Dç”¨ï¼‰
        x = layers.Reshape((self.feature_dim, 1))(inputs)
        
        # Block 1
        x = self.clemnet_block(x, filters=1024, kernel_size=3)
        x = self.clemnet_block(x, filters=512, kernel_size=3)
        x = self.clemnet_block(x, filters=256, kernel_size=3)
        x = self.clemnet_block(x, filters=128, kernel_size=3)
        
        # Flatten
        x = layers.Flatten()(x)
        
        # ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å‡ºåŠ›
        # 1. ã‚¯ãƒªãƒƒã‚¯äºˆæ¸¬
        click_output = layers.Dense(1, activation='sigmoid', name='click')(x)
        
        # 2. ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬
        engagement_output = layers.Dense(1, activation='sigmoid', name='engagement')(x)
        
        # 3. æ»åœ¨æ™‚é–“äºˆæ¸¬
        dwell_output = layers.Dense(1, activation='linear', name='dwell_time')(x)
        
        model = Model(
            inputs=inputs,
            outputs=[click_output, engagement_output, dwell_output]
        )
        
        # é‡ã¿ä»˜ãæå¤±
        model.compile(
            optimizer='adam',
            loss={
                'click': 'binary_crossentropy',
                'engagement': 'binary_crossentropy',
                'dwell_time': 'mse'
            },
            loss_weights={
                'click': 0.5,
                'engagement': 0.3,
                'dwell_time': 0.2
            }
        )
        
        return model
    
    def clemnet_block(self, x, filters, kernel_size):
        """ClemNetãƒ–ãƒ­ãƒƒã‚¯"""
        residual = x
        
        # ChannelWise Dense
        x = layers.Dense(filters, use_bias=False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        
        # Conv1D
        x = layers.Conv1D(filters, kernel_size, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        
        # Residualæ¥ç¶š
        if residual.shape[-1] != filters:
            residual = layers.Conv1D(filters, 1)(residual)
        
        x = layers.Add()([x, residual])
        return x
    
    def extract_rich_features(self, tweet, user):
        """6000æ¬¡å…ƒã®è±Šå¯Œãªç‰¹å¾´é‡"""
        features = []
        
        # 1. ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ï¼ˆBERTç­‰ï¼‰
        features.extend(self.get_text_embedding(tweet.text))  # 768æ¬¡å…ƒ
        
        # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼åŸ‹ã‚è¾¼ã¿ï¼ˆSimClustersï¼‰
        features.extend(self.get_user_embedding(user))  # 145æ¬¡å…ƒ
        
        # 3. ãƒ„ã‚¤ãƒ¼ãƒˆåŸ‹ã‚è¾¼ã¿ï¼ˆSimClustersï¼‰
        features.extend(self.get_tweet_embedding(tweet))  # 145æ¬¡å…ƒ
        
        # 4. ã‚°ãƒ©ãƒ•ç‰¹å¾´ï¼ˆReal Graphï¼‰
        features.extend(self.get_graph_features(user, tweet.author))  # 100æ¬¡å…ƒ
        
        # 5. ç›¸äº’ä½œç”¨ç‰¹å¾´
        features.extend(self.get_interaction_features(user, tweet))  # 500æ¬¡å…ƒ
        
        # 6. çµ±è¨ˆç‰¹å¾´
        features.extend(self.get_statistical_features(tweet))  # 1000æ¬¡å…ƒ
        
        # ... åˆè¨ˆ6000æ¬¡å…ƒ
        
        return np.array(features)
```

## ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè·µ

### ç‰¹å¾´é‡ã®ç¨®é¡ã¨å®Ÿè£…

```python
class FeatureEngineering:
    """åŒ…æ‹¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
    
    def __init__(self):
        self.feature_groups = {
            'static': self.extract_static_features,
            'dynamic': self.extract_dynamic_features,
            'user': self.extract_user_features,
            'context': self.extract_context_features,
            'interaction': self.extract_interaction_features,
            'embedding': self.extract_embedding_features
        }
        
    def extract_all_features(self, tweet, user, context):
        """å…¨ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        all_features = {}
        
        for group_name, extractor in self.feature_groups.items():
            features = extractor(tweet, user, context)
            all_features[group_name] = features
            
        return self.flatten_features(all_features)
    
    def extract_static_features(self, tweet, user, context):
        """é™çš„ç‰¹å¾´ï¼ˆå¤‰åŒ–ã—ãªã„ï¼‰"""
        return {
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            'text_length': len(tweet.text),
            'word_count': len(tweet.text.split()),
            'has_media': int(tweet.media is not None),
            'media_type': self.encode_media_type(tweet.media),
            'has_url': int('http' in tweet.text),
            'url_count': tweet.text.count('http'),
            'hashtag_count': tweet.text.count('#'),
            'mention_count': tweet.text.count('@'),
            
            # è¨€èª
            'language': self.encode_language(tweet.language),
            'is_english': int(tweet.language == 'en'),
            
            # ã‚¿ã‚¤ãƒ—
            'is_reply': int(tweet.in_reply_to is not None),
            'is_retweet': int(tweet.retweeted_status is not None),
            'is_quote': int(tweet.quoted_status is not None),
            
            # ãƒ†ã‚­ã‚¹ãƒˆå“è³ª
            'text_entropy': self.calculate_entropy(tweet.text),
            'readability_score': self.calculate_readability(tweet.text),
            'sentiment_score': self.calculate_sentiment(tweet.text),
        }
    
    def extract_dynamic_features(self, tweet, user, context):
        """å‹•çš„ç‰¹å¾´ï¼ˆæ™‚é–“ã§å¤‰åŒ–ï¼‰"""
        age_seconds = (context.current_time - tweet.created_at).total_seconds()
        
        return {
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ
            'like_count': tweet.like_count,
            'retweet_count': tweet.retweet_count,
            'reply_count': tweet.reply_count,
            'quote_count': tweet.quote_count,
            
            # æ­£è¦åŒ–
            'likes_per_hour': tweet.like_count / (age_seconds / 3600 + 1),
            'retweets_per_hour': tweet.retweet_count / (age_seconds / 3600 + 1),
            
            # æ¯”ç‡
            'engagement_rate': (tweet.like_count + tweet.retweet_count) / (tweet.impression_count + 1),
            'like_rate': tweet.like_count / (tweet.impression_count + 1),
            'retweet_rate': tweet.retweet_count / (tweet.impression_count + 1),
            
            # æ™‚é–“
            'age_seconds': age_seconds,
            'age_hours': age_seconds / 3600,
            'age_days': age_seconds / 86400,
            
            # æ™‚é–“æ¸›è¡°
            'time_decay_1h': np.exp(-age_seconds / 3600),
            'time_decay_24h': np.exp(-age_seconds / 86400),
            'time_decay_7d': np.exp(-age_seconds / 604800),
        }
    
    def extract_user_features(self, tweet, user, context):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ç‰¹å¾´"""
        author = tweet.author
        
        return {
            # åŸºæœ¬çµ±è¨ˆ
            'author_follower_count': author.follower_count,
            'author_following_count': author.following_count,
            'author_tweet_count': author.tweet_count,
            'author_listed_count': author.listed_count,
            
            # æ¯”ç‡
            'author_follower_following_ratio': author.follower_count / (author.following_count + 1),
            'author_tweets_per_day': author.tweet_count / (author.account_age_days + 1),
            
            # å“è³ªæŒ‡æ¨™
            'author_verified': int(author.verified),
            'author_has_bio': int(len(author.bio) > 0),
            'author_has_location': int(author.location is not None),
            'author_has_url': int(author.url is not None),
            
            # Tweepcred
            'author_reputation': self.get_tweepcred_score(author),
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®é–¢ä¿‚
            'user_follows_author': int(author.id in user.following),
            'author_follows_user': int(user.id in author.following),
            'mutual_follow': int(author.id in user.following and user.id in author.following),
        }
    
    def extract_interaction_features(self, tweet, user, context):
        """ç›¸äº’ä½œç”¨ç‰¹å¾´"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®è¡Œå‹•
        user_history = self.get_user_history(user)
        
        return {
            # éå»ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³
            'user_liked_author_before': self.count_past_likes(user, tweet.author),
            'user_retweeted_author_before': self.count_past_retweets(user, tweet.author),
            'user_replied_author_before': self.count_past_replies(user, tweet.author),
            
            # ãƒˆãƒ”ãƒƒã‚¯ã®ä¸€è‡´
            'topic_similarity': self.calculate_topic_similarity(user_history, tweet),
            
            # æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³
            'user_active_now': int(self.is_user_active_time(user, context.current_time)),
            'matches_user_schedule': self.matches_schedule(user, tweet.created_at),
            
            # ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ—ãƒ«ãƒ¼ãƒ•
            'friends_who_liked': self.count_friends_engagement(user, tweet, 'like'),
            'friends_who_retweeted': self.count_friends_engagement(user, tweet, 'retweet'),
        }
    
    def extract_embedding_features(self, tweet, user, context):
        """åŸ‹ã‚è¾¼ã¿ç‰¹å¾´"""
        return {
            # SimClusters
            'simclusters_dot_product': np.dot(
                self.get_user_simclusters(user),
                self.get_tweet_simclusters(tweet)
            ),
            
            # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åŸ‹ã‚è¾¼ã¿
            'semantic_similarity': self.calculate_semantic_similarity(
                user.interests,
                tweet.content
            ),
            
            # ã‚°ãƒ©ãƒ•åŸ‹ã‚è¾¼ã¿
            'graph_distance': self.get_graph_distance(user, tweet.author),
        }
```

## ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰¹å¾´é‡ç®¡ç†

### ç‰¹å¾´é‡ã‚¹ãƒˆã‚¢ã®å®Ÿè£…

```python
import redis
from datetime import datetime, timedelta

class RealtimeFeatureStore:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰¹å¾´é‡ã®ç®¡ç†
    Twitterã¯ Memcached + Manhattan ã‚’ä½¿ç”¨
    """
    
    def __init__(self):
        self.redis = redis.Redis(decode_responses=True)
        self.ttl = 3600  # 1æ™‚é–“
        
    def update_engagement(self, tweet_id, engagement_type, user_id):
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°"""
        # ã‚«ã‚¦ãƒ³ã‚¿ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
        key = f"tweet:{tweet_id}:{engagement_type}"
        self.redis.incr(key)
        
        # æ™‚é–“çª“ã§ã®é›†è¨ˆ
        window_key = f"tweet:{tweet_id}:{engagement_type}:1h:{datetime.now().hour}"
        self.redis.incr(window_key)
        self.redis.expire(window_key, self.ttl)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã®è¨˜éŒ²
        user_key = f"user:{user_id}:{engagement_type}:history"
        self.redis.lpush(user_key, tweet_id)
        self.redis.ltrim(user_key, 0, 999)  # æœ€æ–°1000ä»¶
        
    def get_realtime_features(self, tweet_id):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰¹å¾´é‡ã‚’å–å¾—"""
        features = {}
        
        # ç·è¨ˆ
        features['likes_total'] = int(self.redis.get(f"tweet:{tweet_id}:like") or 0)
        features['retweets_total'] = int(self.redis.get(f"tweet:{tweet_id}:retweet") or 0)
        
        # æ™‚é–“çª“
        current_hour = datetime.now().hour
        features['likes_1h'] = int(
            self.redis.get(f"tweet:{tweet_id}:like:1h:{current_hour}") or 0
        )
        
        # é€Ÿåº¦ï¼ˆã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ/æ™‚é–“ï¼‰
        features['engagement_velocity'] = self.calculate_velocity(tweet_id)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ€§
        features['is_trending'] = self.is_trending(tweet_id)
        
        return features
    
    def calculate_velocity(self, tweet_id):
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé€Ÿåº¦ã‚’è¨ˆç®—"""
        # éå»1æ™‚é–“ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå±¥æ­´
        history = []
        for i in range(60):  # éå»60åˆ†
            minute = (datetime.now() - timedelta(minutes=i)).minute
            key = f"tweet:{tweet_id}:engagement:minute:{minute}"
            count = int(self.redis.get(key) or 0)
            history.append(count)
            
        # åŠ é€Ÿåº¦ã‚’è¨ˆç®—
        if len(history) > 1:
            recent = sum(history[:10])
            past = sum(history[10:20])
            velocity = (recent - past) / (past + 1)
            return velocity
        return 0
    
    def is_trending(self, tweet_id):
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š"""
        velocity = self.calculate_velocity(tweet_id)
        total_engagement = int(self.redis.get(f"tweet:{tweet_id}:engagement") or 0)
        
        # æ€¥é€Ÿã«ä¼¸ã³ã¦ã„ã‚‹ && ä¸€å®šä»¥ä¸Šã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ
        return velocity > 2.0 and total_engagement > 100
```

## ğŸ“Š å­¦ç¿’ã¨Evaluation

### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
class OnlineLearningPipeline:
    """
    ç¶™ç¶šçš„ãªå­¦ç¿’ã¨æ”¹å–„
    """
    
    def __init__(self):
        self.model = HeavyRanker()
        self.feature_store = RealtimeFeatureStore()
        self.training_buffer = []
        
    def collect_training_data(self, impression):
        """ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""
        features = self.extract_features(impression)
        
        # ãƒ©ãƒ™ãƒ«ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ï¼‰
        labels = {
            'clicked': impression.clicked,
            'engaged': impression.liked or impression.retweeted,
            'dwell_time': impression.dwell_time_seconds
        }
        
        self.training_buffer.append((features, labels))
        
        # ãƒãƒƒãƒ•ã‚¡ãŒæº€ãŸã•ã‚ŒãŸã‚‰å­¦ç¿’
        if len(self.training_buffer) >= 1000:
            self.train_batch()
            
    def train_batch(self):
        """ãƒãƒƒãƒå­¦ç¿’"""
        X = np.array([f for f, _ in self.training_buffer])
        y = {
            'click': np.array([l['clicked'] for _, l in self.training_buffer]),
            'engagement': np.array([l['engaged'] for _, l in self.training_buffer]),
            'dwell_time': np.array([l['dwell_time'] for _, l in self.training_buffer])
        }
        
        # å­¦ç¿’
        self.model.model.fit(X, y, epochs=1, batch_size=32)
        
        # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
        self.training_buffer = []
        
    def evaluate(self, test_data):
        """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""
        metrics = {
            'auc_click': self.calculate_auc(test_data, 'click'),
            'auc_engagement': self.calculate_auc(test_data, 'engagement'),
            'rmse_dwell': self.calculate_rmse(test_data, 'dwell_time'),
            'ndcg@10': self.calculate_ndcg(test_data, k=10)
        }
        
        return metrics
```

## ğŸ¯ æ¼”ç¿’å•é¡Œ

### æ¼”ç¿’4-1: ã‚«ã‚¹ã‚¿ãƒ ç‰¹å¾´é‡ã®ä½œæˆ
```python
def create_custom_features(tweet, user):
    """
    ç‹¬è‡ªã®ç‰¹å¾´é‡ã‚’3ã¤ä½œæˆã—ã¦ãã ã•ã„
    ä¾‹ï¼šçµµæ–‡å­—ã®æ•°ã€è³ªå•ã®æœ‰ç„¡ã€ãªã©
    """
    # TODO: å®Ÿè£…
    pass
```

### æ¼”ç¿’4-2: Light Rankerã®æœ€é©åŒ–
```python
def optimize_light_ranker(training_data):
    """
    Light Rankerã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–
    """
    # TODO: å®Ÿè£…
    pass
```

## ğŸ“š ã¾ã¨ã‚

- **2æ®µéšãƒ©ãƒ³ã‚­ãƒ³ã‚°**: é€Ÿåº¦ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è§£æ±º
- **Light Ranker**: ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿã€æœ€å°é™ã®ç‰¹å¾´é‡
- **Heavy Ranker**: è¤‡é›‘ã§ç²¾å¯†ã€è±Šå¯Œãªç‰¹å¾´é‡
- **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: é™çš„/å‹•çš„/ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®çµ„ã¿åˆã‚ã›
- **ç¶™ç¶šçš„å­¦ç¿’**: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§æ”¹å–„ã—ç¶šã‘ã‚‹

[â†’ Chapter 5: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªè¨­è¨ˆã¸](chapter05_scalable_design.md)